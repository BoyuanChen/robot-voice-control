<launch>
    <!--

    -->

    <!-- If 1, start speech-to-text -->
    <arg name="start_stt" default="1"/>
    <!-- If 1, start microphone -->
    <arg name="microphone" default="1"/>

    <!-- Microphone (audio capture) -->
    <node name="microphone_capture" pkg="audio_capture" type="audio_capture"
          if="$(arg microphone)">
        <param name="bitrate" value="128"/>
    </node>

    <!-- subscribe to /audio ROS messages -->
    <node name="recognizer" pkg="pocketsphinx" type="recognizer.py"
          output="log"
          if="$(arg start_stt)">
        <param name="lm"
               value="$(find robot_voice_control)/language_models/kuka_teaching_commands.lm"/>
        <param name="dict"
               value="$(find robot_voice_control)/language_models/kuka_teaching_commands.dict"/>
        <param name="audio_msg_topic" value="/audio"/>
        <remap from="~output" to="nl_command_parsed"/>
    </node>

    <!-- load parameters that specify the available commands -->
    <rosparam
            file="$(find robot_voice_control)/config/kuka_teaching_commands.yaml"
            command="load"/>

    <!-- This node maps from NL -> control tokens. -->
    <node name="kuka_voice_control"
          pkg="robot_voice_control"
          type="message_control.py"
          output="screen" >
    </node>

</launch>
